[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "I am a PhD student in Special Education and Clinical Science at the University of Oregon, specializing in Educational Data Science. My research focuses on improving outcomes for students with disabilities, particularly through early intervention and autism research. I study how evidence-based interventions can support the development of learning-related social skills in young children, ensuring they have a strong foundation for future success.\nAs a Precision Teacher and Behavior Analyst, I use precise behavioral measurement and educational data science to refine interventions and assess their broader impact. One of my primary research methodologies is evidence synthesis through systematic literature reviews and meta-analyses, which allows me to evaluate the effectiveness of interventions and translate findings into meaningful practice and policy recommendations. My work is grounded in the belief that data-driven decision-making can enhance teaching practices and lead to meaningful improvements in student outcomes.\nBefore pursuing my PhD, I worked as a special education teacher, where I gained firsthand experience in developing individualized instruction for students with diverse learning needs. That experience continues to shape my research and reinforces my dedication to bridging the gap between research and practice. Through my work, I aim to contribute to a more equitable education system where all students, especially those with disabilities, receive the support they need to thrive.\nThis blog highlights my research in special education, early intervention, autism, and educational data science. My goal is to share insights that bridge the gap between research and practice, informing educators, practitioners, and policymakers.\n\nContact\nFeel free to contact me via email at smeans@uoregon.edu"
  },
  {
    "objectID": "posts/mypost/mypost.html",
    "href": "posts/mypost/mypost.html",
    "title": "Post With Code",
    "section": "",
    "text": "test"
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "This is a post with executable code.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Exploring PT Math pinpoints",
    "section": "",
    "text": "This following post utilized data from a private precision teaching clinic in the United States. Each student in this data has a score for accuracy and fluency of math pinpoints at intake and then their score for those skills on a CBM after 40 hours of instruction.\nThis report includes: Sample visualizations to understand participant distribution. Data reshaping to convert the dataset into a tidy format. Analysis for three research questions using clustering, regression, and t-tests.\n###Research Questions and Methods:###\nBefore reading in the data, I cleaned it in a different script so that I could remove the names and replace with unique id numbers (to protect student privacy).\nIn this project, the first step I took was to load all required R packages. For data manipulation (tidyverse), visualizations (ggplot2), XXXXXXX, and running regression models (lme4).\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(ggplot2)\nlibrary(cluster)\nlibrary(broom)\nlibrary(lme4)\n\nLoading required package: Matrix\n\nAttaching package: 'Matrix'\n\nThe following objects are masked from 'package:tidyr':\n\n    expand, pack, unpack\nNext I read in the data from my local and then used (glimpse) to see an overview of the data.\nfile_path &lt;- \"/Users/saratessapalos/Desktop/FIT learning/fitdata/data/Cleaned_Data1.csv\"\ndf &lt;- read_csv(file_path)\n\nNew names:\nRows: 279 Columns: 453\n── Column specification\n──────────────────────────────────────────────────────── Delimiter: \",\" chr\n(452): Diagnosis, Grade Level, Skip Count by 10 Forwards to 1,000...4, .... dbl\n(1): Participant_ID\nℹ Use `spec()` to retrieve the full column specification for this data. ℹ\nSpecify the column types or set `show_col_types = FALSE` to quiet this message.\n• `Skip Count by 10 Forwards to 1,000` -&gt; `Skip Count by 10 Forwards to\n  1,000...4`\n• `` -&gt; `...5`\n• `` -&gt; `...6`\n• `` -&gt; `...7`\n• `` -&gt; `...8`\n• `` -&gt; `...10`\n• `` -&gt; `...11`\n• `` -&gt; `...12`\n• `` -&gt; `...13`\n• `Skip Count by 100 Forwards to 10,000` -&gt; `Skip Count by 100 Forwards to\n  10,000...14`\n• `` -&gt; `...15`\n• `` -&gt; `...16`\n• `` -&gt; `...17`\n• `` -&gt; `...18`\n• `` -&gt; `...20`\n• `` -&gt; `...21`\n• `` -&gt; `...22`\n• `` -&gt; `...23`\n• `Skip Count by 2 Forwards to 200` -&gt; `Skip Count by 2 Forwards to 200...24`\n• `` -&gt; `...25`\n• `` -&gt; `...26`\n• `` -&gt; `...27`\n• `` -&gt; `...28`\n• `Skip Count by 2 Backwards from 200` -&gt; `Skip Count by 2 Backwards from\n  200...29`\n• `` -&gt; `...30`\n• `` -&gt; `...31`\n• `` -&gt; `...32`\n• `` -&gt; `...33`\n• `Skip Count by 5 Forwards to 500` -&gt; `Skip Count by 5 Forwards to 500...34`\n• `` -&gt; `...35`\n• `` -&gt; `...36`\n• `` -&gt; `...37`\n• `` -&gt; `...38`\n• `Skip Count by 5 Backwards from 500` -&gt; `Skip Count by 5 Backwards from\n  500...39`\n• `` -&gt; `...40`\n• `` -&gt; `...41`\n• `` -&gt; `...42`\n• `` -&gt; `...43`\n• `` -&gt; `...45`\n• `` -&gt; `...46`\n• `` -&gt; `...47`\n• `` -&gt; `...48`\n• `` -&gt; `...50`\n• `` -&gt; `...51`\n• `` -&gt; `...52`\n• `` -&gt; `...53`\n• `` -&gt; `...55`\n• `` -&gt; `...56`\n• `` -&gt; `...57`\n• `` -&gt; `...58`\n• `Skip Count by 10 Forwards to 1,000` -&gt; `Skip Count by 10 Forwards to\n  1,000...59`\n• `` -&gt; `...60`\n• `` -&gt; `...61`\n• `` -&gt; `...62`\n• `` -&gt; `...63`\n• `` -&gt; `...65`\n• `` -&gt; `...66`\n• `` -&gt; `...67`\n• `` -&gt; `...68`\n• `Skip Count by 100 Forwards to 10,000` -&gt; `Skip Count by 100 Forwards to\n  10,000...69`\n• `` -&gt; `...70`\n• `` -&gt; `...71`\n• `` -&gt; `...72`\n• `` -&gt; `...73`\n• `` -&gt; `...75`\n• `` -&gt; `...76`\n• `` -&gt; `...77`\n• `` -&gt; `...78`\n• `Skip Count by 2 Forwards to 200` -&gt; `Skip Count by 2 Forwards to 200...79`\n• `` -&gt; `...80`\n• `` -&gt; `...81`\n• `` -&gt; `...82`\n• `` -&gt; `...83`\n• `Skip Count by 2 Backwards from 200` -&gt; `Skip Count by 2 Backwards from\n  200...84`\n• `` -&gt; `...85`\n• `` -&gt; `...86`\n• `` -&gt; `...87`\n• `` -&gt; `...88`\n• `` -&gt; `...90`\n• `` -&gt; `...91`\n• `` -&gt; `...92`\n• `` -&gt; `...93`\n• `` -&gt; `...95`\n• `` -&gt; `...96`\n• `` -&gt; `...97`\n• `` -&gt; `...98`\n• `` -&gt; `...100`\n• `` -&gt; `...101`\n• `` -&gt; `...102`\n• `` -&gt; `...103`\n• `` -&gt; `...105`\n• `` -&gt; `...106`\n• `` -&gt; `...107`\n• `` -&gt; `...108`\n• `Skip Count by 5 Forwards to 500` -&gt; `Skip Count by 5 Forwards to 500...109`\n• `` -&gt; `...110`\n• `` -&gt; `...111`\n• `` -&gt; `...112`\n• `` -&gt; `...113`\n• `Skip Count by 5 Backwards from 500` -&gt; `Skip Count by 5 Backwards from\n  500...114`\n• `` -&gt; `...115`\n• `` -&gt; `...116`\n• `` -&gt; `...117`\n• `` -&gt; `...118`\n• `` -&gt; `...120`\n• `` -&gt; `...121`\n• `` -&gt; `...122`\n• `` -&gt; `...123`\n• `` -&gt; `...125`\n• `` -&gt; `...126`\n• `` -&gt; `...127`\n• `` -&gt; `...128`\n• `` -&gt; `...130`\n• `` -&gt; `...131`\n• `` -&gt; `...132`\n• `` -&gt; `...133`\n• `` -&gt; `...135`\n• `` -&gt; `...136`\n• `` -&gt; `...137`\n• `` -&gt; `...138`\n• `` -&gt; `...140`\n• `` -&gt; `...141`\n• `` -&gt; `...142`\n• `` -&gt; `...143`\n• `` -&gt; `...145`\n• `` -&gt; `...146`\n• `` -&gt; `...147`\n• `` -&gt; `...148`\n• `` -&gt; `...150`\n• `` -&gt; `...151`\n• `` -&gt; `...152`\n• `` -&gt; `...153`\n• `` -&gt; `...155`\n• `` -&gt; `...156`\n• `` -&gt; `...157`\n• `` -&gt; `...158`\n• `` -&gt; `...160`\n• `` -&gt; `...161`\n• `` -&gt; `...162`\n• `` -&gt; `...163`\n• `` -&gt; `...165`\n• `` -&gt; `...166`\n• `` -&gt; `...167`\n• `` -&gt; `...168`\n• `` -&gt; `...170`\n• `` -&gt; `...171`\n• `` -&gt; `...172`\n• `` -&gt; `...173`\n• `` -&gt; `...175`\n• `` -&gt; `...176`\n• `` -&gt; `...177`\n• `` -&gt; `...178`\n• `` -&gt; `...180`\n• `` -&gt; `...181`\n• `` -&gt; `...182`\n• `` -&gt; `...183`\n• `` -&gt; `...185`\n• `` -&gt; `...186`\n• `` -&gt; `...187`\n• `` -&gt; `...188`\n• `` -&gt; `...190`\n• `` -&gt; `...191`\n• `` -&gt; `...192`\n• `` -&gt; `...193`\n• `` -&gt; `...195`\n• `` -&gt; `...196`\n• `` -&gt; `...197`\n• `` -&gt; `...198`\n• `` -&gt; `...200`\n• `` -&gt; `...201`\n• `` -&gt; `...202`\n• `` -&gt; `...203`\n• `` -&gt; `...205`\n• `` -&gt; `...206`\n• `` -&gt; `...207`\n• `` -&gt; `...208`\n• `` -&gt; `...210`\n• `` -&gt; `...211`\n• `` -&gt; `...212`\n• `` -&gt; `...213`\n• `` -&gt; `...215`\n• `` -&gt; `...216`\n• `` -&gt; `...217`\n• `` -&gt; `...218`\n• `` -&gt; `...220`\n• `` -&gt; `...221`\n• `` -&gt; `...222`\n• `` -&gt; `...223`\n• `` -&gt; `...225`\n• `` -&gt; `...226`\n• `` -&gt; `...227`\n• `` -&gt; `...228`\n• `` -&gt; `...230`\n• `` -&gt; `...231`\n• `` -&gt; `...232`\n• `` -&gt; `...233`\n• `` -&gt; `...235`\n• `` -&gt; `...236`\n• `` -&gt; `...237`\n• `` -&gt; `...238`\n• `` -&gt; `...240`\n• `` -&gt; `...241`\n• `` -&gt; `...242`\n• `` -&gt; `...243`\n• `` -&gt; `...245`\n• `` -&gt; `...246`\n• `` -&gt; `...247`\n• `` -&gt; `...248`\n• `` -&gt; `...250`\n• `` -&gt; `...251`\n• `` -&gt; `...252`\n• `` -&gt; `...253`\n• `` -&gt; `...255`\n• `` -&gt; `...256`\n• `` -&gt; `...257`\n• `` -&gt; `...258`\n• `` -&gt; `...260`\n• `` -&gt; `...261`\n• `` -&gt; `...262`\n• `` -&gt; `...263`\n• `` -&gt; `...265`\n• `` -&gt; `...266`\n• `` -&gt; `...267`\n• `` -&gt; `...268`\n• `` -&gt; `...270`\n• `` -&gt; `...271`\n• `` -&gt; `...272`\n• `` -&gt; `...273`\n• `` -&gt; `...275`\n• `` -&gt; `...276`\n• `` -&gt; `...277`\n• `` -&gt; `...278`\n• `` -&gt; `...280`\n• `` -&gt; `...281`\n• `` -&gt; `...282`\n• `` -&gt; `...283`\n• `` -&gt; `...285`\n• `` -&gt; `...286`\n• `` -&gt; `...287`\n• `` -&gt; `...288`\n• `` -&gt; `...290`\n• `` -&gt; `...291`\n• `` -&gt; `...292`\n• `` -&gt; `...293`\n• `` -&gt; `...295`\n• `` -&gt; `...296`\n• `` -&gt; `...297`\n• `` -&gt; `...298`\n• `` -&gt; `...300`\n• `` -&gt; `...301`\n• `` -&gt; `...302`\n• `` -&gt; `...303`\n• `` -&gt; `...305`\n• `` -&gt; `...306`\n• `` -&gt; `...307`\n• `` -&gt; `...308`\n• `` -&gt; `...310`\n• `` -&gt; `...311`\n• `` -&gt; `...312`\n• `` -&gt; `...313`\n• `` -&gt; `...315`\n• `` -&gt; `...316`\n• `` -&gt; `...317`\n• `` -&gt; `...318`\n• `` -&gt; `...320`\n• `` -&gt; `...321`\n• `` -&gt; `...322`\n• `` -&gt; `...323`\n• `` -&gt; `...325`\n• `` -&gt; `...326`\n• `` -&gt; `...327`\n• `` -&gt; `...328`\n• `` -&gt; `...330`\n• `` -&gt; `...331`\n• `` -&gt; `...332`\n• `` -&gt; `...333`\n• `` -&gt; `...335`\n• `` -&gt; `...336`\n• `` -&gt; `...337`\n• `` -&gt; `...338`\n• `` -&gt; `...340`\n• `` -&gt; `...341`\n• `` -&gt; `...342`\n• `` -&gt; `...343`\n• `` -&gt; `...345`\n• `` -&gt; `...346`\n• `` -&gt; `...347`\n• `` -&gt; `...348`\n• `` -&gt; `...350`\n• `` -&gt; `...351`\n• `` -&gt; `...352`\n• `` -&gt; `...353`\n• `` -&gt; `...355`\n• `` -&gt; `...356`\n• `` -&gt; `...357`\n• `` -&gt; `...358`\n• `` -&gt; `...360`\n• `` -&gt; `...361`\n• `` -&gt; `...362`\n• `` -&gt; `...363`\n• `` -&gt; `...365`\n• `` -&gt; `...366`\n• `` -&gt; `...367`\n• `` -&gt; `...368`\n• `` -&gt; `...370`\n• `` -&gt; `...371`\n• `` -&gt; `...372`\n• `` -&gt; `...373`\n• `` -&gt; `...375`\n• `` -&gt; `...376`\n• `` -&gt; `...377`\n• `` -&gt; `...378`\n• `` -&gt; `...380`\n• `` -&gt; `...381`\n• `` -&gt; `...382`\n• `` -&gt; `...383`\n• `` -&gt; `...385`\n• `` -&gt; `...386`\n• `` -&gt; `...387`\n• `` -&gt; `...388`\n• `` -&gt; `...390`\n• `` -&gt; `...391`\n• `` -&gt; `...392`\n• `` -&gt; `...393`\n• `` -&gt; `...395`\n• `` -&gt; `...396`\n• `` -&gt; `...397`\n• `` -&gt; `...398`\n• `` -&gt; `...400`\n• `` -&gt; `...401`\n• `` -&gt; `...402`\n• `` -&gt; `...403`\n• `` -&gt; `...405`\n• `` -&gt; `...406`\n• `` -&gt; `...407`\n• `` -&gt; `...408`\n• `` -&gt; `...410`\n• `` -&gt; `...411`\n• `` -&gt; `...412`\n• `` -&gt; `...413`\n• `Number Comparison Fluency - Pairs...413` -&gt; `Number Comparison Fluency -\n  Pairs`\n• `` -&gt; `...415`\n• `` -&gt; `...416`\n• `` -&gt; `...417`\n• `` -&gt; `...418`\n• `` -&gt; `...419`\n• `` -&gt; `...420`\n• `` -&gt; `...422`\n• `` -&gt; `...423`\n• `` -&gt; `...424`\n• `` -&gt; `...425`\n• `` -&gt; `...426`\n• `` -&gt; `...427`\n• `` -&gt; `...429`\n• `` -&gt; `...430`\n• `` -&gt; `...431`\n• `` -&gt; `...432`\n• `` -&gt; `...433`\n• `` -&gt; `...434`\n• `` -&gt; `...435`\n• `` -&gt; `...436`\n• `` -&gt; `...437`\n• `` -&gt; `...438`\n• `` -&gt; `...439`\n• `` -&gt; `...440`\n• `` -&gt; `...441`\n• `` -&gt; `...443`\n• `` -&gt; `...444`\n• `` -&gt; `...445`\n• `` -&gt; `...446`\n• `` -&gt; `...447`\n• `` -&gt; `...448`\n• `` -&gt; `...450`\n• `` -&gt; `...451`\n• `` -&gt; `...452`\n• `` -&gt; `...453`\nNext, I visualized the sample participants."
  },
  {
    "objectID": "posts/welcome/index.html#reshape-data-to-tidy-format",
    "href": "posts/welcome/index.html#reshape-data-to-tidy-format",
    "title": "Exploring PT Math pinpoints",
    "section": "Reshape Data to Tidy Format",
    "text": "Reshape Data to Tidy Format\n[edit this now that changes were made]I reshaped the dataset to a “tidy” format, where each row represents: Participant_ID, Grade Level, Diagnosis, Skill, Measure` (Intake Accuracy, Post Fluency, etc.), Score. I converted categorical variables to factors to avoid regression errors. And I removed levels with only one category to prevent contrast errors in regression.\n\n# Start with clean data (row 4 onwards)\nclean_df &lt;- df[4:nrow(df), ]\n\n# Step 2: Create proper column names by combining rows 1 and 2\ncol_names_skill &lt;- as.character(unlist(df[1, ]))\ncol_names_assessment &lt;- as.character(unlist(df[2, ]))\n\n# Fix any NA or empty values in column names\ncol_names_skill &lt;- ifelse(is.na(col_names_skill) | col_names_skill == \"\", paste0(\"Column_\", 1:length(col_names_skill)), col_names_skill)\ncol_names_assessment &lt;- ifelse(is.na(col_names_assessment) | col_names_assessment == \"\", \"Unknown\", col_names_assessment)\n\n# Create combined names for all columns\nfull_col_names &lt;- vector(\"character\", length(col_names_skill))\nfor(i in 1:length(col_names_skill)) {\n  if(i &lt;= 3) {\n    # Keep the original names for the first three columns\n    full_col_names[i] &lt;- col_names_skill[i]\n  } else {\n    # Combine skill and assessment type for data columns\n    full_col_names[i] &lt;- paste(col_names_skill[i], col_names_assessment[i], sep = \"_\")\n  }\n}\n\n# Make sure all column names are unique\nif(any(duplicated(full_col_names))) {\n  # Add a suffix to duplicated names\n  dups &lt;- which(duplicated(full_col_names))\n  for(i in dups) {\n    full_col_names[i] &lt;- paste0(full_col_names[i], \"_\", i)\n  }\n}\n\n# Assign the new column names\ncolnames(clean_df) &lt;- full_col_names\n\n# Step 3: Convert to tidy format\ntidy_df &lt;- clean_df %&gt;%\n  # Convert character columns to numeric (except first 3 columns)\n  mutate(across(4:ncol(.), ~as.numeric(as.character(.)))) %&gt;%\n  # Convert to long format\n  pivot_longer(\n    cols = 4:ncol(.),\n    names_to = \"Skill_Measure\",\n    values_to = \"Score\"\n  ) %&gt;%\n  # Split Skill_Measure into Skill and Measure\n  # Use a more flexible pattern to handle different formats\n  separate(Skill_Measure, \n           into = c(\"Skill\", \"Measure\"),\n           sep = \"_(?=(Intake|Post|Targeted)($|_))\",  # Split before Intake, Post, or Targeted\n           fill = \"right\") %&gt;%  # Handle any missing values\n  # Remove any trailing/leading whitespace\n  mutate(\n    Skill = trimws(Skill),\n    Measure = trimws(Measure)\n  )\n\nWarning: There were 5 warnings in `mutate()`.\nThe first warning was:\nℹ In argument: `across(4:ncol(.), ~as.numeric(as.character(.)))`.\nCaused by warning:\n! NAs introduced by coercion\nℹ Run `dplyr::last_dplyr_warnings()` to see the 4 remaining warnings.\n\n\n\n# Check the number of NAs in the Score column\nna_count &lt;- sum(is.na(tidy_df$Score))\ntotal_count &lt;- nrow(tidy_df)\nna_percentage &lt;- (na_count / total_count) * 100\n\n# Print summary\ncat(\"Total rows:\", total_count, \"\\n\")\n\nTotal rows: 124200 \n\ncat(\"NA values in Score:\", na_count, \"\\n\")\n\nNA values in Score: 47403 \n\ncat(\"Percentage NA:\", na_percentage, \"%\\n\")\n\nPercentage NA: 38.16667 %\n\n# See what the tidy data looks like\nhead(tidy_df)\n\n# A tibble: 6 × 6\n  Column_1 Column_2 Column_3  Skill                                Measure Score\n     &lt;dbl&gt; &lt;chr&gt;    &lt;chr&gt;     &lt;chr&gt;                                &lt;chr&gt;   &lt;dbl&gt;\n1        3 None     2nd Grade Skip Count by 10 Forwards to 1,000 … &lt;NA&gt;       84\n2        3 None     2nd Grade Skip Count by 10 Forwards to 1,000 … &lt;NA&gt;      100\n3        3 None     2nd Grade Skip Count by 10 Forwards to 1,000 … &lt;NA&gt;       92\n4        3 None     2nd Grade Skip Count by 10 Forwards to 1,000 … &lt;NA&gt;      100\n5        3 None     2nd Grade Skip Count by 10 Forwards to 1,000 … &lt;NA&gt;        0\n6        3 None     2nd Grade Skip Count by 10 Backwards From 1,0… &lt;NA&gt;       NA\n\n\n////// ## Answer Research Questions\n\nQ1: What math skills, when grouped, predict other skills?\nto address this I used a Correlation analysis to identify skills that improve together. Then I did Association rule mining to find patterns where mastering one skill predicts mastery of another. I then created the following visualizations: a correlation heatmap and association rule graph.\n\n# Create a correlation matrix for skill scores\n\n\n# Visualize correlation matrix"
  },
  {
    "objectID": "posts/welcome/index.html#answer-research-questions",
    "href": "posts/welcome/index.html#answer-research-questions",
    "title": "Exploring PT Math pinpoints",
    "section": "4. Answer Research Questions",
    "text": "4. Answer Research Questions\n\nQ1: What math skills, when grouped, predict other skills?\nto address this I XXXXX"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Research Blog",
    "section": "",
    "text": "Exploring PT Math pinpoints\n\n\n\n\n\n\nPrecision Teaching\n\n\nMath Instruction\n\n\nClustering\n\n\n\n\n\n\n\n\n\nFeb 27, 2025\n\n\nSaratessa\n\n\n\n\n\n\n\n\n\n\n\n\nPost With Code\n\n\n\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\nFeb 26, 2025\n\n\nSaratessa Palos\n\n\n\n\n\n\n\n\n\n\n\n\nPost With Code\n\n\n\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\nFeb 26, 2025\n\n\nSaratessa Palos\n\n\n\n\n\n\nNo matching items"
  }
]