{
  "hash": "617fa50ff24326835cc2a89ef54b90e7",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Exploring PT Math pinpoints\"\nauthor: \"Saratessa\"\ndate: \"2025-02-27\"\ncategories: [Precision Teaching, Math Instruction, Clustering]\n---\n\n\n\nThis following post utilized data from a private precision teaching clinic in the United States. Each student in this data has a score for accuracy and fluency of math pinpoints at intake and then their score for those skills on a CBM after 40 hours of instruction.\n\nThis report includes: **Sample visualizations** to understand participant distribution. **Data reshaping** to convert the dataset into a tidy format. **Analysis for three research questions** using clustering, regression, and t-tests.\n\n**###Research Questions and Methods:###**\n\n1.  **What math skills, when grouped, predict other skills?**\n\n    -   **Hierarchical clustering** is used to group skills that show similar learning patterns, helping identify which skills are related to others.\n    \n\n2.  **What math skills predict outcomes on the CBM after 40 hours of instruction?**\n\n    -   **A multiple regression model** is used.\n\n3.  **How do targeted versus untargeted math skills relate to CBM outcomes?**\n\n    -   **ANCOVA** is used.\n\nBefore reading in the data, I cleaned it in a different script so that I could remove the names and replace with unique id numbers (to protect student privacy).\n\nIn this project, the first step I took was to load all required R packages. For data manipulation (`tidyverse`), visualizations (`ggplot2`), XXXXXXX, and running regression models (`lme4`).\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n```\n\n\n:::\n\n```{.r .cell-code}\nlibrary(ggplot2)\nlibrary(cluster)\nlibrary(broom)\nlibrary(lme4)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nLoading required package: Matrix\n\nAttaching package: 'Matrix'\n\nThe following objects are masked from 'package:tidyr':\n\n    expand, pack, unpack\n```\n\n\n:::\n:::\n\n\n\nNext I read in the data from my local and then used (`glimpse`) to see an overview of the data.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfile_path <- \"/Users/saratessapalos/Desktop/FIT learning/fitdata/data/Cleaned_Data1.csv\"\ndf <- read_csv(file_path)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nNew names:\nRows: 279 Columns: 453\n── Column specification\n──────────────────────────────────────────────────────── Delimiter: \",\" chr\n(452): Diagnosis, Grade Level, Skip Count by 10 Forwards to 1,000...4, .... dbl\n(1): Participant_ID\nℹ Use `spec()` to retrieve the full column specification for this data. ℹ\nSpecify the column types or set `show_col_types = FALSE` to quiet this message.\n• `Skip Count by 10 Forwards to 1,000` -> `Skip Count by 10 Forwards to\n  1,000...4`\n• `` -> `...5`\n• `` -> `...6`\n• `` -> `...7`\n• `` -> `...8`\n• `` -> `...10`\n• `` -> `...11`\n• `` -> `...12`\n• `` -> `...13`\n• `Skip Count by 100 Forwards to 10,000` -> `Skip Count by 100 Forwards to\n  10,000...14`\n• `` -> `...15`\n• `` -> `...16`\n• `` -> `...17`\n• `` -> `...18`\n• `` -> `...20`\n• `` -> `...21`\n• `` -> `...22`\n• `` -> `...23`\n• `Skip Count by 2 Forwards to 200` -> `Skip Count by 2 Forwards to 200...24`\n• `` -> `...25`\n• `` -> `...26`\n• `` -> `...27`\n• `` -> `...28`\n• `Skip Count by 2 Backwards from 200` -> `Skip Count by 2 Backwards from\n  200...29`\n• `` -> `...30`\n• `` -> `...31`\n• `` -> `...32`\n• `` -> `...33`\n• `Skip Count by 5 Forwards to 500` -> `Skip Count by 5 Forwards to 500...34`\n• `` -> `...35`\n• `` -> `...36`\n• `` -> `...37`\n• `` -> `...38`\n• `Skip Count by 5 Backwards from 500` -> `Skip Count by 5 Backwards from\n  500...39`\n• `` -> `...40`\n• `` -> `...41`\n• `` -> `...42`\n• `` -> `...43`\n• `` -> `...45`\n• `` -> `...46`\n• `` -> `...47`\n• `` -> `...48`\n• `` -> `...50`\n• `` -> `...51`\n• `` -> `...52`\n• `` -> `...53`\n• `` -> `...55`\n• `` -> `...56`\n• `` -> `...57`\n• `` -> `...58`\n• `Skip Count by 10 Forwards to 1,000` -> `Skip Count by 10 Forwards to\n  1,000...59`\n• `` -> `...60`\n• `` -> `...61`\n• `` -> `...62`\n• `` -> `...63`\n• `` -> `...65`\n• `` -> `...66`\n• `` -> `...67`\n• `` -> `...68`\n• `Skip Count by 100 Forwards to 10,000` -> `Skip Count by 100 Forwards to\n  10,000...69`\n• `` -> `...70`\n• `` -> `...71`\n• `` -> `...72`\n• `` -> `...73`\n• `` -> `...75`\n• `` -> `...76`\n• `` -> `...77`\n• `` -> `...78`\n• `Skip Count by 2 Forwards to 200` -> `Skip Count by 2 Forwards to 200...79`\n• `` -> `...80`\n• `` -> `...81`\n• `` -> `...82`\n• `` -> `...83`\n• `Skip Count by 2 Backwards from 200` -> `Skip Count by 2 Backwards from\n  200...84`\n• `` -> `...85`\n• `` -> `...86`\n• `` -> `...87`\n• `` -> `...88`\n• `` -> `...90`\n• `` -> `...91`\n• `` -> `...92`\n• `` -> `...93`\n• `` -> `...95`\n• `` -> `...96`\n• `` -> `...97`\n• `` -> `...98`\n• `` -> `...100`\n• `` -> `...101`\n• `` -> `...102`\n• `` -> `...103`\n• `` -> `...105`\n• `` -> `...106`\n• `` -> `...107`\n• `` -> `...108`\n• `Skip Count by 5 Forwards to 500` -> `Skip Count by 5 Forwards to 500...109`\n• `` -> `...110`\n• `` -> `...111`\n• `` -> `...112`\n• `` -> `...113`\n• `Skip Count by 5 Backwards from 500` -> `Skip Count by 5 Backwards from\n  500...114`\n• `` -> `...115`\n• `` -> `...116`\n• `` -> `...117`\n• `` -> `...118`\n• `` -> `...120`\n• `` -> `...121`\n• `` -> `...122`\n• `` -> `...123`\n• `` -> `...125`\n• `` -> `...126`\n• `` -> `...127`\n• `` -> `...128`\n• `` -> `...130`\n• `` -> `...131`\n• `` -> `...132`\n• `` -> `...133`\n• `` -> `...135`\n• `` -> `...136`\n• `` -> `...137`\n• `` -> `...138`\n• `` -> `...140`\n• `` -> `...141`\n• `` -> `...142`\n• `` -> `...143`\n• `` -> `...145`\n• `` -> `...146`\n• `` -> `...147`\n• `` -> `...148`\n• `` -> `...150`\n• `` -> `...151`\n• `` -> `...152`\n• `` -> `...153`\n• `` -> `...155`\n• `` -> `...156`\n• `` -> `...157`\n• `` -> `...158`\n• `` -> `...160`\n• `` -> `...161`\n• `` -> `...162`\n• `` -> `...163`\n• `` -> `...165`\n• `` -> `...166`\n• `` -> `...167`\n• `` -> `...168`\n• `` -> `...170`\n• `` -> `...171`\n• `` -> `...172`\n• `` -> `...173`\n• `` -> `...175`\n• `` -> `...176`\n• `` -> `...177`\n• `` -> `...178`\n• `` -> `...180`\n• `` -> `...181`\n• `` -> `...182`\n• `` -> `...183`\n• `` -> `...185`\n• `` -> `...186`\n• `` -> `...187`\n• `` -> `...188`\n• `` -> `...190`\n• `` -> `...191`\n• `` -> `...192`\n• `` -> `...193`\n• `` -> `...195`\n• `` -> `...196`\n• `` -> `...197`\n• `` -> `...198`\n• `` -> `...200`\n• `` -> `...201`\n• `` -> `...202`\n• `` -> `...203`\n• `` -> `...205`\n• `` -> `...206`\n• `` -> `...207`\n• `` -> `...208`\n• `` -> `...210`\n• `` -> `...211`\n• `` -> `...212`\n• `` -> `...213`\n• `` -> `...215`\n• `` -> `...216`\n• `` -> `...217`\n• `` -> `...218`\n• `` -> `...220`\n• `` -> `...221`\n• `` -> `...222`\n• `` -> `...223`\n• `` -> `...225`\n• `` -> `...226`\n• `` -> `...227`\n• `` -> `...228`\n• `` -> `...230`\n• `` -> `...231`\n• `` -> `...232`\n• `` -> `...233`\n• `` -> `...235`\n• `` -> `...236`\n• `` -> `...237`\n• `` -> `...238`\n• `` -> `...240`\n• `` -> `...241`\n• `` -> `...242`\n• `` -> `...243`\n• `` -> `...245`\n• `` -> `...246`\n• `` -> `...247`\n• `` -> `...248`\n• `` -> `...250`\n• `` -> `...251`\n• `` -> `...252`\n• `` -> `...253`\n• `` -> `...255`\n• `` -> `...256`\n• `` -> `...257`\n• `` -> `...258`\n• `` -> `...260`\n• `` -> `...261`\n• `` -> `...262`\n• `` -> `...263`\n• `` -> `...265`\n• `` -> `...266`\n• `` -> `...267`\n• `` -> `...268`\n• `` -> `...270`\n• `` -> `...271`\n• `` -> `...272`\n• `` -> `...273`\n• `` -> `...275`\n• `` -> `...276`\n• `` -> `...277`\n• `` -> `...278`\n• `` -> `...280`\n• `` -> `...281`\n• `` -> `...282`\n• `` -> `...283`\n• `` -> `...285`\n• `` -> `...286`\n• `` -> `...287`\n• `` -> `...288`\n• `` -> `...290`\n• `` -> `...291`\n• `` -> `...292`\n• `` -> `...293`\n• `` -> `...295`\n• `` -> `...296`\n• `` -> `...297`\n• `` -> `...298`\n• `` -> `...300`\n• `` -> `...301`\n• `` -> `...302`\n• `` -> `...303`\n• `` -> `...305`\n• `` -> `...306`\n• `` -> `...307`\n• `` -> `...308`\n• `` -> `...310`\n• `` -> `...311`\n• `` -> `...312`\n• `` -> `...313`\n• `` -> `...315`\n• `` -> `...316`\n• `` -> `...317`\n• `` -> `...318`\n• `` -> `...320`\n• `` -> `...321`\n• `` -> `...322`\n• `` -> `...323`\n• `` -> `...325`\n• `` -> `...326`\n• `` -> `...327`\n• `` -> `...328`\n• `` -> `...330`\n• `` -> `...331`\n• `` -> `...332`\n• `` -> `...333`\n• `` -> `...335`\n• `` -> `...336`\n• `` -> `...337`\n• `` -> `...338`\n• `` -> `...340`\n• `` -> `...341`\n• `` -> `...342`\n• `` -> `...343`\n• `` -> `...345`\n• `` -> `...346`\n• `` -> `...347`\n• `` -> `...348`\n• `` -> `...350`\n• `` -> `...351`\n• `` -> `...352`\n• `` -> `...353`\n• `` -> `...355`\n• `` -> `...356`\n• `` -> `...357`\n• `` -> `...358`\n• `` -> `...360`\n• `` -> `...361`\n• `` -> `...362`\n• `` -> `...363`\n• `` -> `...365`\n• `` -> `...366`\n• `` -> `...367`\n• `` -> `...368`\n• `` -> `...370`\n• `` -> `...371`\n• `` -> `...372`\n• `` -> `...373`\n• `` -> `...375`\n• `` -> `...376`\n• `` -> `...377`\n• `` -> `...378`\n• `` -> `...380`\n• `` -> `...381`\n• `` -> `...382`\n• `` -> `...383`\n• `` -> `...385`\n• `` -> `...386`\n• `` -> `...387`\n• `` -> `...388`\n• `` -> `...390`\n• `` -> `...391`\n• `` -> `...392`\n• `` -> `...393`\n• `` -> `...395`\n• `` -> `...396`\n• `` -> `...397`\n• `` -> `...398`\n• `` -> `...400`\n• `` -> `...401`\n• `` -> `...402`\n• `` -> `...403`\n• `` -> `...405`\n• `` -> `...406`\n• `` -> `...407`\n• `` -> `...408`\n• `` -> `...410`\n• `` -> `...411`\n• `` -> `...412`\n• `` -> `...413`\n• `Number Comparison Fluency - Pairs...413` -> `Number Comparison Fluency -\n  Pairs`\n• `` -> `...415`\n• `` -> `...416`\n• `` -> `...417`\n• `` -> `...418`\n• `` -> `...419`\n• `` -> `...420`\n• `` -> `...422`\n• `` -> `...423`\n• `` -> `...424`\n• `` -> `...425`\n• `` -> `...426`\n• `` -> `...427`\n• `` -> `...429`\n• `` -> `...430`\n• `` -> `...431`\n• `` -> `...432`\n• `` -> `...433`\n• `` -> `...434`\n• `` -> `...435`\n• `` -> `...436`\n• `` -> `...437`\n• `` -> `...438`\n• `` -> `...439`\n• `` -> `...440`\n• `` -> `...441`\n• `` -> `...443`\n• `` -> `...444`\n• `` -> `...445`\n• `` -> `...446`\n• `` -> `...447`\n• `` -> `...448`\n• `` -> `...450`\n• `` -> `...451`\n• `` -> `...452`\n• `` -> `...453`\n```\n\n\n:::\n:::\n\n\n\nNext, I visualized the sample participants.\n\n### Explanation:\n\n-   These visualizations help us **understand the sample** by showing:\n    -   How many students have a **diagnosis**.\n    -   The **grade distribution**.\n    -   The **types of diagnoses** in the dataset.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n### Students With vs. Without Diagnosis\ndf %>% \n  mutate(Has_Diagnosis = ifelse(Diagnosis == \"None\" | is.na(Diagnosis), \"No Diagnosis\", \"Has Diagnosis\")) %>%\n  count(Has_Diagnosis) %>%\n  ggplot(aes(x = Has_Diagnosis, y = n, fill = Has_Diagnosis)) +\n  geom_bar(stat = \"identity\", color = \"black\") +\n  labs(title = \"Students With vs. Without Diagnosis\",\n       x = \"Diagnosis Status\",\n       y = \"Count\") +\n  scale_fill_manual(values = c(\"salmon\", \"skyblue\"))\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n\n```{.r .cell-code}\n### Grade Level Distribution\ndf %>%\n  filter(!is.na(`Grade Level`)) %>%\n  count(`Grade Level`) %>%\n  ggplot(aes(x = reorder(`Grade Level`, n), y = n)) +\n  geom_bar(stat = \"identity\", fill = \"steelblue\", color = \"black\") +\n  labs(title = \"Grade Level Distribution\",\n       x = \"Grade Level\",\n       y = \"Count\") +\n  coord_flip()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-3-2.png){width=672}\n:::\n\n```{.r .cell-code}\n### Diagnosis Type Count\ndf %>%\n  mutate(Diagnosis_Category = case_when(\n    Diagnosis == \"Mood Disorder - Anxiety (e.g. selective mutism, anxiety, GAD)\" ~ \"Mood Disorder\",\n    Diagnosis == \"Learning Disability - Speech and language - Speech delay\" ~ \"Learning Disability\",\n    Diagnosis == \"None\" | is.na(Diagnosis) ~ \"None\"\n  )) %>%\n  count(Diagnosis_Category) %>%\n  ggplot(aes(x = Diagnosis_Category, y = n, fill = Diagnosis_Category)) +\n  geom_col(color = \"black\") +\n  labs(title = \"Diagnosis Type Count\",\n       x = \"Diagnosis Type\",\n       y = \"Count\") +\n  scale_fill_manual(values = c(\"lightcoral\", \"steelblue\", \"gray\"))\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-3-3.png){width=672}\n:::\n:::\n\n\n\n## Reshape Data to Tidy Format\n\n[edit this now that changes were made]I reshaped the dataset to a \"tidy\" format, where each row represents: Participant_ID, Grade Level, Diagnosis, Skill, Measure\\` (Intake Accuracy, Post Fluency, etc.), Score. I converted categorical variables to factors to avoid regression errors. And I removed levels with only one category to prevent contrast errors in regression.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Start with clean data (row 4 onwards)\nclean_df <- df[4:nrow(df), ]\n\n# Step 2: Create proper column names by combining rows 1 and 2\ncol_names_skill <- as.character(unlist(df[1, ]))\ncol_names_assessment <- as.character(unlist(df[2, ]))\n\n# Fix any NA or empty values in column names\ncol_names_skill <- ifelse(is.na(col_names_skill) | col_names_skill == \"\", paste0(\"Column_\", 1:length(col_names_skill)), col_names_skill)\ncol_names_assessment <- ifelse(is.na(col_names_assessment) | col_names_assessment == \"\", \"Unknown\", col_names_assessment)\n\n# Create combined names for all columns\nfull_col_names <- vector(\"character\", length(col_names_skill))\nfor(i in 1:length(col_names_skill)) {\n  if(i <= 3) {\n    # Keep the original names for the first three columns\n    full_col_names[i] <- col_names_skill[i]\n  } else {\n    # Combine skill and assessment type for data columns\n    full_col_names[i] <- paste(col_names_skill[i], col_names_assessment[i], sep = \"_\")\n  }\n}\n\n# Make sure all column names are unique\nif(any(duplicated(full_col_names))) {\n  # Add a suffix to duplicated names\n  dups <- which(duplicated(full_col_names))\n  for(i in dups) {\n    full_col_names[i] <- paste0(full_col_names[i], \"_\", i)\n  }\n}\n\n# Assign the new column names\ncolnames(clean_df) <- full_col_names\n\n# Step 3: Convert to tidy format\ntidy_df <- clean_df %>%\n  # Convert character columns to numeric (except first 3 columns)\n  mutate(across(4:ncol(.), ~as.numeric(as.character(.)))) %>%\n  # Convert to long format\n  pivot_longer(\n    cols = 4:ncol(.),\n    names_to = \"Skill_Measure\",\n    values_to = \"Score\"\n  ) %>%\n  # Split Skill_Measure into Skill and Measure\n  # Use a more flexible pattern to handle different formats\n  separate(Skill_Measure, \n           into = c(\"Skill\", \"Measure\"),\n           sep = \"_(?=(Intake|Post|Targeted)($|_))\",  # Split before Intake, Post, or Targeted\n           fill = \"right\") %>%  # Handle any missing values\n  # Remove any trailing/leading whitespace\n  mutate(\n    Skill = trimws(Skill),\n    Measure = trimws(Measure)\n  )\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: There were 5 warnings in `mutate()`.\nThe first warning was:\nℹ In argument: `across(4:ncol(.), ~as.numeric(as.character(.)))`.\nCaused by warning:\n! NAs introduced by coercion\nℹ Run `dplyr::last_dplyr_warnings()` to see the 4 remaining warnings.\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Check the number of NAs in the Score column\nna_count <- sum(is.na(tidy_df$Score))\ntotal_count <- nrow(tidy_df)\nna_percentage <- (na_count / total_count) * 100\n\n# Print summary\ncat(\"Total rows:\", total_count, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nTotal rows: 124200 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"NA values in Score:\", na_count, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nNA values in Score: 47403 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Percentage NA:\", na_percentage, \"%\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nPercentage NA: 38.16667 %\n```\n\n\n:::\n\n```{.r .cell-code}\n# See what the tidy data looks like\nhead(tidy_df)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 6\n  Column_1 Column_2 Column_3  Skill                                Measure Score\n     <dbl> <chr>    <chr>     <chr>                                <chr>   <dbl>\n1        3 None     2nd Grade Skip Count by 10 Forwards to 1,000 … <NA>       84\n2        3 None     2nd Grade Skip Count by 10 Forwards to 1,000 … <NA>      100\n3        3 None     2nd Grade Skip Count by 10 Forwards to 1,000 … <NA>       92\n4        3 None     2nd Grade Skip Count by 10 Forwards to 1,000 … <NA>      100\n5        3 None     2nd Grade Skip Count by 10 Forwards to 1,000 … <NA>        0\n6        3 None     2nd Grade Skip Count by 10 Backwards From 1,0… <NA>       NA\n```\n\n\n:::\n:::\n\n\n\n//////\n## Answer Research Questions\n\n### **Q1: What math skills, when grouped, predict other skills?**\n\nto address this I used a **Correlation analysis** to identify skills that **improve together**.\nThen I did **Association rule mining** to find patterns where mastering one skill predicts mastery of another.\nI then created the following visualizations: a **correlation heatmap** and **association rule graph**.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create a correlation matrix for skill scores\n\n\n# Visualize correlation matrix\n```\n:::\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}